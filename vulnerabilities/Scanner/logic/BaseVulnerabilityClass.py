from bs4 import BeautifulSoup
from urlparse import urlparse, urljoin
import mechanize
from methods import GetFormInputFields, ParseFormsSQLI
import time

class BaseVulnerabilityClass():

    def __init__(self, timestamp, cookie_jar):
        self.__timestamp = timestamp
        self.__cookie_jar = cookie_jar

    def init_mechanize(self):
        self.br = mechanize.Browser()
        # self.UpdateCookiesQttoMechanize()
        self.br.set_cookiejar(self.__cookie_jar)

        # Browser options - have to understand what each of them means
        self.br.set_handle_equiv(True)
        self.br.set_handle_gzip(True)
        self.br.set_handle_redirect(True)
        self.br.set_handle_referer(True)
        self.br.set_handle_robots(False)
        self.br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(),
                                   max_time=1)  # Follows refresh 0 but not hangs on refresh > 1
        # Want debugging messages?
        # br.set_debug_http(True)
        # br.set_debug_redirects(True)
        # br.set_debug_responses(True)

        # User-Agent
        self.br.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/534.34 \
        (KHTML, like Gecko) Chrome/53.0.2785.113 Safari/534.34')]

    def get_injection_points(self, links):
        """return dictionary containing a url and its form/parsed link objects"""
        forms = {}
        links = {}
        for link in links:
            domain = urlparse(link).hostname
            response = unicode(self.br.open(link).read(), 'utf-8')
            self.soup = BeautifulSoup(response, 'html.parser')
            links_list = self.extract_links(link, domain)
            forms_list = self.extract_forms()
            links[link] = links_list
            forms[link] = {}
            for form in forms_list:
                (method, inputnames, inputnonames) = GetFormInputFields(link, form)
                str_inputnames = {}
                for k, v in inputnames.iteritems():
                    str_inputnames[k] = unicode(v).encode('utf-8')
                inputnames = str_inputnames
                forms[link][form] = (method, inputnames, inputnonames)
        return forms, links

    def extract_links(self, link, domain):
        links_list = []
        embedded_links = self.soup.findAll(name='a')
        for embedded_link in embedded_links:
            if embedded_link.has_attr('href'):
                href_full_link = urljoin(link, embedded_link['href'])
                if urlparse(href_full_link).hostname == domain:
                    links_list.append(href_full_link)  # print href_full_link
        print ("[*] Number of links: " + str(len(links_list)))
        return links_list

    def extract_forms(self):
        return self.soup.findAll(name='form', action=True)

    def get_url_open_results(self, method, data, url):
        check_r = True
        if method.lower() == "post":
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url, data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False

                self.event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "<br><h2>Data:</h2> " + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                # print "[+] ***Original HTML response***\n    Maybe XSS: payload "+response+" return in the response, \
                # URL: "+self.urlform+" payload: "+data+"\n\n"
                self.add_event()
        else:
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url + "?" + data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False
                self.event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "?" + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                self.add_event()
        if check_r:
            # self.UpdateCookiesMechanizetoQt()
            htmlresponse = unicode(r.read(), 'utf-8')
            elapsed_time = end - start
            response_hash = self.hash_page(htmlresponse)
            return [htmlresponse, response_hash, elapsed_time]