from bs4 import BeautifulSoup
from urlparse import urlparse, urljoin
import mechanize

import RXSSCrud
from Methods import GetFormInputFields
import time
import base64
import hashlib
import re
from cookielib import Cookie
from VulnerabilitiesObjects import SimpleVulnerabilityEntity
import VulnerabilitiesCRUD
import SQLICrud
from ConfigParser import RawConfigParser
from CredentialsObject import CredentialsEntity
from cookieExpiration import CookieException


class VulnerabilityUtils():

    def __init__(self, tableName, scanType, credentialsEntity=None):
        self.__tableName = tableName
        self.__scanType = scanType
        self.__credentialsEntity = credentialsEntity
        self.get_configuration_properties()
        if scanType == 'ALL':
            self.errorBasedPayloads = self.get_payloads_by_type(payload_type=self.error_based)
            self.errorBasedResponses = self.get_error_based_responses()
            ALLPAYLOADS = 1000
            self.rxssPayloads = self.__getRXSSPayloads(page=0, size=ALLPAYLOADS)
            self.timeBasedPayloads = self.get_payloads_by_type(payload_type=self.time_based)
        elif scanType == 'SQLI':
            self.errorBasedPayloads = self.get_payloads_by_type(payload_type=self.error_based)
            self.errorBasedResponses = self.get_error_based_responses()
            self.timeBasedPayloads = self.get_payloads_by_type(payload_type=self.time_based)
        elif scanType == 'RXSS':
            ALLPAYLOADS = 1000
            self.rxssPayloads = self.__getRXSSPayloads(page=0, size=ALLPAYLOADS)
        self.sessions = []
        self.br = mechanize.Browser()
        self.cookie_jar = mechanize.CookieJar()
        self.init_mechanize()

    def get_configuration_properties(self):
        self.config = RawConfigParser()
        self.config.read('../common/config.properties')

        self.env_type = self.config.get('CurrentEnvironment', 'type')

        # means for authentication
        self.cookie = self.config.get('Authentication', 'Cookie')
        self.baseAuth = self.config.get('Authentication', 'BasicAuthentication')

        self.error_based = self.config.get('SQLITypes', 'error_based')
        self.time_based = self.config.get('SQLITypes', 'time_based')

    def __getRXSSPayloads(self, page=0, size=0):
        return RXSSCrud.getRXSSPayloads(self.env_type, page=page, size=size)

    def get_payloads_by_type(self, payload_type):
        payloads = []
        i = 0
        page_result = SQLICrud.getPayloadsByType(self.env_type, type=payload_type, page=i)
        while page_result:
            for payload in page_result:
                payloads.append(payload)
            i += 1
            page_result = SQLICrud.getPayloadsByType(self.env_type, type=payload_type, page=i)
        return payloads

    def get_error_based_responses(self):
        error_based_responses = []
        i = 0
        page_result = SQLICrud.getResponses(self.env_type, page=i)
        while page_result:
            for response in page_result:
                error_based_responses.append(response)
            i += 1
            page_result = SQLICrud.getResponses(self.env_type, page=i)
        return error_based_responses

    def getCookieJar(self):
        return self.cookie_jar

    def getErrorBasedPayloads(self):
        return self.errorBasedPayloads

    def getTimeBasedPayloads(self):
        return self.timeBasedPayloads

    def getRXSSPayloads(self):
        return self.rxssPayloads

    def getErrorBasedResponses(self):
        return self.errorBasedResponses

    def init_mechanize(self):
        self.br.set_cookiejar(self.cookie_jar)

        # Browser options - have to understand what each of them means
        self.br.set_handle_equiv(True)
        self.br.set_handle_gzip(True)
        self.br.set_handle_redirect(True)
        self.br.set_handle_referer(True)
        self.br.set_handle_robots(False)
        self.br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(),
                                   max_time=1)  # Follows refresh 0 but not hangs on refresh > 1
        # Want debugging messages?
        # br.set_debug_http(True)
        # br.set_debug_redirects(True)
        # br.set_debug_responses(True)

        # User-Agent
        self.br.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/534.34 \
        (KHTML, like Gecko) Chrome/53.0.2785.113 Safari/534.34')]

    def updateAuthenticationMethod(self, sessionEntity, url):
        if sessionEntity is None:
            return
        elif sessionEntity.getType() == 'Cookie':  # TODO - shouldn't be hard coded
            for cookie in sessionEntity.getValue():
                if cookie not in self.sessions:
                    self.addCookie(cookie, url)
                    self.sessions.append(cookie)
        elif sessionEntity.getType() == 'BaseAuth':  # TODO - shouldn't be hard coded
            if sessionEntity.getValue() not in self.sessions:
                self.addBaseAuthHeader(sessionEntity.getValue())
                # TODO: does a list of python need to be comprised of same elements only?
                self.sessions.append(sessionEntity.getValue())

    def addCookie(self, cookie, url):
        new_cookie = Cookie(version=0, name=str(cookie["name"]), value=str(cookie["value"]), port=None,
                            port_specified=False, domain=str(cookie["domain"]),
                            domain_specified=False,
                            domain_initial_dot=False, path=str(cookie["path"]), path_specified=True, secure=False,
                            expires=None,  # should change when I have cookie boundary
                            discard=True, comment=None, comment_url=None, rest={}, rfc2109=False)
        self.cookie_jar.set_cookie(new_cookie)

    def addBaseAuthHeader(self, sessionValue):
        # TODO: understand whether this adds headers also for future requests (that might need cookie instead)
        self.br.addheaders.append(('Authorization', sessionValue))

    def get_injection_points(self, pageEntity, sessionEntity):
        self.updateAuthenticationMethod(sessionEntity, pageEntity.getURL())
        ######################################################
        # this section should only be applied in sqli algorithm tests
        # try:
        #     self.verifyHash(url=pageEntity.getURL(), expected_hash=pageEntity.getPageHash())
        # except:
        #     self.generateNewCookie()
        ######################################################
        # self.generateNewCookie()
        self.verifyHash(url=pageEntity.getURL(), expected_hash=pageEntity.getPageHash())
        forms = {}
        domain = urlparse(pageEntity.getURL()).hostname
        response = unicode(self.br.open(pageEntity.getURL()).read(), 'utf-8')
        soup = BeautifulSoup(response, 'html.parser')
        links = self.extract_links(pageEntity.getURL(), domain, soup)
        forms_list = self.extract_forms(soup)
        for form in forms_list:
            (method, inputnames, inputnonames) = GetFormInputFields(pageEntity.getURL(), form)
            str_inputnames = {}
            for k, v in inputnames.iteritems():
                str_inputnames[k] = unicode(v).encode('utf-8')
            inputnames = str_inputnames
            forms[form] = (method, inputnames, inputnonames)
        return forms, links

    def extract_links(self, url, domain, soup):
        links_list = []
        embedded_links = soup.findAll(name='a')
        for embedded_link in embedded_links:
            if embedded_link.has_attr('href'):
                href_full_link = urljoin(url, embedded_link['href'])
                if urlparse(href_full_link).hostname == domain:
                    links_list.append(href_full_link)  # print href_full_link
        print ("[*] Number of links: " + str(len(links_list)))
        return links_list

    def extract_forms(self, soup):
        return soup.findAll(name='form', action=True)

    def get_url_open_results(self, method, data, url):
        check_r = True
        if method.lower() == "post":
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url, data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False

                event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "<br><h2>Data:</h2> " + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                print(
                    event)  # print "[+] ***Original HTML response***\n    Maybe XSS: payload "+response+" return in the response, \  # URL: "+self.urlform+" payload: "+data+"\n\n"  # self.add_event()
        else:
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url + "?" + data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False
                event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "?" + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                print(event)  # self.add_event()
        if check_r:
            # self.UpdateCookiesMechanizetoQt()
            htmlresponse = unicode(r.read(), 'utf-8')
            elapsed_time = end - start
            response_hash = self.hash_page(htmlresponse)
            request = str(method) + "\n" + "url = " + url + "\n" + "fullpayload = " + data
            return [htmlresponse, response_hash, elapsed_time, base64.b64encode(request)]

    def hash_page(self, page):
        self.hashSoup = BeautifulSoup(page, 'html.parser')
        self.remove_changing_attributes_from_soup()
        return hashlib.md5(str(self.hashSoup)).digest()

    def remove_changing_attributes_from_soup(self):
        tags_to_remove = self.hashSoup.find_all(value=re.compile('[-a-zA-Z0-9+_/]{50,}'))
        for tag in tags_to_remove:
            tag.decompose()

    def add_event(self, name=None, url=None, payload=None, requestB64=None):
        simpleVulnerability = SimpleVulnerabilityEntity(name=name, url=url, payload=payload, requestB64=requestB64)
        createdVuln = VulnerabilitiesCRUD.createVulnerability(simpleVulnerability, self.__tableName, self.env_type)
        print(createdVuln.getRequestB64())

    def verifyHash(self, url, expected_hash):
        r = self.br.open(url)
        if r._url != url:
            # TODO - if it's a different url - shouldn't we just raise cookieException?
            content_length = str(0)
        else:
            # content_length = str(r._headers["content-length"])
            content_length = str(len(str(r.read())))
        hash = hashlib.md5(url + content_length).digest().encode("hex")
        if hash != expected_hash:
            print ("hash not equal")
            raise CookieException()

    def generateNewCookie(self, credentialsEntity=None):
        print("Entered Generate new cookie Function")
        if credentialsEntity is not None:
            self.__credentialsEntity = credentialsEntity
        self.br.open(self.__credentialsEntity.getLoginInfo()["formAction"])
        self.br.select_form(nr=0)  # TODO: Zur what if the login form is not the first form?
        for attribute in self.__credentialsEntity.getLoginInfo()["form"]:
            try:
                self.br.form[attribute] = self.__credentialsEntity.getLoginInfo()["form"][attribute]
            except:
                continue
        self.br.submit()
