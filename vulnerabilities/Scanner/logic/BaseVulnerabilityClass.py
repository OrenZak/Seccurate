from bs4 import BeautifulSoup
from urlparse import urlparse, urljoin
import mechanize

import RXSSCrud
from Methods import GetFormInputFields, ParseFormsSQLI
import time
import base64
import hashlib
import re
from cookielib import Cookie
from SessionObject import SessionEntity
from VulnerabilitiesObjects import SimpleVulnerabilityEntity
import VulnerabilitiesCRUD
import SQLICrud
from ConfigParser import RawConfigParser


class VulnerabilityUtils():

    def __init__(self, tableName, scanType):
        self.__tableName = tableName
        self.__scanType = scanType
        self.get_configuration_properties()
        if scanType == 'ALL':
            self.errorBasedPayloads = self.get_payloads_by_type(payload_type=self.error_based)
            self.errorBasedResponses = self.get_error_based_responses()
            ALLPAYLOADS = 1000
            self.rxssPayloads = self.__getRXSSPayloads(page=0, size=ALLPAYLOADS)
        elif scanType == 'SQLI':
            self.errorBasedPayloads = self.get_payloads_by_type(payload_type=self.error_based)
            self.errorBasedResponses = self.get_error_based_responses()
        elif scanType == 'RXSS':
            ALLPAYLOADS = 1000
            self.rxssPayloads = self.__getRXSSPayloads(page=0, size=ALLPAYLOADS)
        self.sessionEntity = SessionEntity(None, '')
        self.br = mechanize.Browser()
        self.cookie_jar = mechanize.CookieJar()
        self.init_mechanize()

    def get_configuration_properties(self):
        self.config = RawConfigParser()
        self.config.read('..\common\config.properties')

        # means for authentication
        self.cookie = self.config.get('Authentication', 'Cookie')
        self.baseAuth = self.config.get('Authentication', 'BasicAuthentication')

        self.error_based = self.config.get('SQLITypes', 'error_based')

    def __getRXSSPayloads(self, page=0, size=0):
        return RXSSCrud.getRXSSPayloads(page=page, size=size)

    def get_payloads_by_type(self, payload_type):
        payloads = []
        i = 0
        page_result = SQLICrud.getPayloadsByType(type=payload_type, page=i)
        while page_result:
            for payload in page_result:
                payloads.append(payload)
            i += 1
            page_result = SQLICrud.getPayloadsByType(type=payload_type, page=i)
        return payloads

    def get_error_based_responses(self):
        error_based_responses = []
        i = 0
        page_result = SQLICrud.getResponses(page=i)
        while page_result:
            for response in page_result:
                error_based_responses.append(response)
            i += 1
            page_result = SQLICrud.getResponses(page=i)
        return error_based_responses

    def getCookieJar(self):
        return self.cookie_jar

    def getErrorBasedPayloads(self):
        return self.errorBasedPayloads

    def getRXSSPayloads(self):
        return self.rxssPayloads

    def getErrorBasedResponses(self):
        return self.errorBasedResponses

    def init_mechanize(self):
        self.br.set_cookiejar(self.cookie_jar)

        # Browser options - have to understand what each of them means
        self.br.set_handle_equiv(True)
        self.br.set_handle_gzip(True)
        self.br.set_handle_redirect(True)
        self.br.set_handle_referer(True)
        self.br.set_handle_robots(False)
        self.br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(),
                                   max_time=1)  # Follows refresh 0 but not hangs on refresh > 1
        # Want debugging messages?
        # br.set_debug_http(True)
        # br.set_debug_redirects(True)
        # br.set_debug_responses(True)

        # User-Agent
        self.br.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/534.34 \
        (KHTML, like Gecko) Chrome/53.0.2785.113 Safari/534.34')]

    def updateAuthenticationMethod(self, sessionEntity):
        if self.sessionEntity.getType() is None:
            self.sessionEntity.setType(sessionEntity.getType())
        currentValues = self.sessionEntity.getValuesList()
        if sessionEntity.getType() == 'Cookie':
            for cookie in sessionEntity.getValue().split(';'):
                if cookie not in currentValues:
                    self.addCookie(cookie)
                    self.addValueToSessionEntityValues(cookie)
        elif sessionEntity.getType() == 'BaseAuth':
            if sessionEntity.getValue() not in currentValues:
                self.addBaseAuthHeader(sessionEntity.getValue())
                self.addValueToSessionEntityValues(sessionEntity.getValue())

    def addCookie(self, cookie):
        # TODO - will we have problems if server would specify domain?
        # TODO: change '=' delimiter according to Zur's decision
        self.cookie_jar.set_cookie(
            Cookie(version=0, name=str(cookie).split('=')[0], value=str(cookie).split('=')[1], port=None,
                   port_specified=False, domain=str(cookie).split('=')[2], domain_specified=False,
                   domain_initial_dot=False, path=str(cookie).split('=')[3], path_specified=True, secure=False,
                   expires=None,  # should change when I have cookie boundary
                   discard=True, comment=None, comment_url=None, rest={}, rfc2109=False))

    def addBaseAuthHeader(self, sessionValue):
        # TODO: understand whether this adds headers also for future requests (that might need cookie instead)
        self.br.addheaders.append(('Authorization', sessionValue))

    def addValueToSessionEntityValues(self, value):
        self.sessionEntity.setValue(self.sessionEntity.getValue() + ';' + value)

    def get_injection_points(self, pageEntity, sessionEntity):
        """return dictionary containing a url and its form/parsed link objects"""
        self.updateAuthenticationMethod(sessionEntity)
        forms = {}
        # links = []
        domain = urlparse(pageEntity.getURL()).hostname
        response = unicode(self.br.open(pageEntity.getURL()).read(), 'utf-8')
        soup = BeautifulSoup(response, 'html.parser')
        links = self.extract_links(pageEntity.getURL(), domain, soup)
        forms_list = self.extract_forms(soup)
        for form in forms_list:
            (method, inputnames, inputnonames) = GetFormInputFields(pageEntity.getURL(), form)
            str_inputnames = {}
            for k, v in inputnames.iteritems():
                str_inputnames[k] = unicode(v).encode('utf-8')
            inputnames = str_inputnames
            forms[form] = (method, inputnames, inputnonames)
        return forms, links

    def extract_links(self, url, domain, soup):
        links_list = []
        embedded_links = soup.findAll(name='a')
        for embedded_link in embedded_links:
            if embedded_link.has_attr('href'):
                href_full_link = urljoin(url, embedded_link['href'])
                if urlparse(href_full_link).hostname == domain:
                    links_list.append(href_full_link)  # print href_full_link
        print ("[*] Number of links: " + str(len(links_list)))
        return links_list

    def extract_forms(self, soup):
        return soup.findAll(name='form', action=True)

    def get_url_open_results(self, method, data, url):
        check_r = True
        if method.lower() == "post":
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url, data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False

                event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "<br><h2>Data:</h2> " + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                print(
                    event)  # print "[+] ***Original HTML response***\n    Maybe XSS: payload "+response+" return in the response, \  # URL: "+self.urlform+" payload: "+data+"\n\n"  # self.add_event()
        else:
            try:
                # Get Response From the Server
                start = time.time()
                r = self.br.open(url + "?" + data.encode('utf-8'))
                end = time.time()
            except Exception as e:
                check_r = False
                event = "<h1>[-]Error:<h1><h2>URL:</h2> " + url + "?" + data.encode(
                    'utf-8') + "<br><h2>Error: </h2>" + str(e) + "<br><br><br><br>"
                print(event)  # self.add_event()
        if check_r:
            # self.UpdateCookiesMechanizetoQt()
            htmlresponse = unicode(r.read(), 'utf-8')
            elapsed_time = end - start
            response_hash = self.hash_page(htmlresponse)
            request = str(method) + "\n" + "url = " + url + "\n" + "fullpayload = " + data
            return [htmlresponse, response_hash, elapsed_time, base64.b64encode(request)]

    def hash_page(self, page):
        self.hashSoup = BeautifulSoup(page, 'html.parser')
        self.remove_changing_attributes_from_soup()
        return hashlib.md5(str(self.hashSoup)).digest()

    def remove_changing_attributes_from_soup(self):
        tags_to_remove = self.hashSoup.find_all(value=re.compile('[-a-zA-Z0-9+_/]{50,}'))
        for tag in tags_to_remove:
            tag.decompose()

    def add_event(self, name=None, url=None, payload=None, requestB64=None):
        simpleVulnerability = SimpleVulnerabilityEntity(name=name, url=url, payload=payload, requestB64=requestB64)
        createdVuln = VulnerabilitiesCRUD.createVulnerability(simpleVulnerability, self.__tableName)
        print(createdVuln.getRequestB64())
